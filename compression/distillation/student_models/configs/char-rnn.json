{
    "embedding-dim": 100,
    "encoder-hidden-dim": 150,
    "cls-hidden-dim": 200,
    "bidirectional": true,
    "batch-size": 50,
    "num-layers": 1,
    "lr": 5e-4,
    "weight-decay": 1e-5,
    "dropout": 0.2,
    "type": "lstm",
    "embedding-type": "bpe",
    "vocab-size": 5000,
    "hash-ratio": 10,
    "num-hashes": 3
}