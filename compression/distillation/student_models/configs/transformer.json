{
    "embedding-dim" : 50,
    "vocab-size": 3000,
    "cls-hidden-dim": 100,
    "dropout": 0.2,
    "lr": 1e-04,
    "weight-decay": 0.1,
    "batch-size": 50,
    "encoder-hidden-dim": 128,
    "rho": 0.95,
    "hash-ratio": 10,
    "num-hashes": 3,
    "embedding-type": "hash",
    "type": "transformer",
    "attn-heads": 5,
    "attn-hidden": 500,
    "num-layers": 12,
    "train-masking": 0.1,
    "max-tokens": 128,
    "clip-grad": 0.5,
    "cls-init-range": 0.1,
    "emb-init-range": 0.1
}